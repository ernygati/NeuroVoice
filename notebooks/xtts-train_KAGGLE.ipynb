{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13347073,"sourceType":"datasetVersion","datasetId":8375486}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –∏ –±–∏–±–ª–∏–æ—Ç–µ–∫ (~5–º–∏–Ω)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-10-12T09:33:30.252603Z","iopub.execute_input":"2025-10-12T09:33:30.252945Z","iopub.status.idle":"2025-10-12T09:33:30.256419Z","shell.execute_reply.started":"2025-10-12T09:33:30.252925Z","shell.execute_reply":"2025-10-12T09:33:30.255699Z"}}},{"cell_type":"code","source":"!git clone https://github.com/ernygati/NeuroVoice.git\nimport os\nos.chdir(\"/kaggle/working/NeuroVoice\")\n!pip install pyyaml>=6.0.2 transformers==4.35.2 tts==0.22.0 torch==2.5.1 pyzmq==26.4.0 ipykernel==6.20.2 soxr==0.3.7 graphviz==0.20.3 matplotlib==3.8.0 onnx==1.16.2 onnxruntime==1.16.3 openpyxl==3.1.2 tensorboard==2.19.0 tensorboard-data-server==0.7.2 torchmetrics==1.7.0 torchview==0.2.6 tqdm==4.67.1 typing-extensions==4.13.0 openai-whisper>=20250625 -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:23:10.256738Z","iopub.execute_input":"2025-10-12T09:23:10.256984Z","iopub.status.idle":"2025-10-12T09:28:45.488091Z","shell.execute_reply.started":"2025-10-12T09:23:10.256961Z","shell.execute_reply":"2025-10-12T09:28:45.487133Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'NeuroVoice'...\nremote: Enumerating objects: 304, done.\u001b[K\nremote: Counting objects: 100% (304/304), done.\u001b[K\nremote: Compressing objects: 100% (203/203), done.\u001b[K\nremote: Total 304 (delta 60), reused 290 (delta 49), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (304/304), 5.72 MiB | 16.98 MiB/s, done.\nResolving deltas: 100% (60/60), done.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.21 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ncudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nvisions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.7.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.20.2 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 1.5.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nsklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.2 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.2 which is incompatible.\nscikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\nnx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.1.0 which is incompatible.\ntorchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.5.1 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\nmizani 0.13.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\nplotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 1.5.3 which is incompatible.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.19.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nxarray 2025.3.1 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n\n–í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –æ—Ç—Å—É—Å—Ç–≤–æ–≤–∞—Ç—å, –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –∫–æ–¥ –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —ç—Ç–∏—Ö —Ñ–∞–π–ª–æ–≤ (‚ö†Ô∏è –ù–£–ñ–ù–û GPU ‚ö†Ô∏è)\n\n–°–æ–≤–µ—Ç—ã:\n- –¥–ª—è —Å—Ç–∞—Ä—Ç–∞ –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –¥–æ .pth —Ñ–∞–π–ª–∞, –∑–∞–¥–∞–≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `CHECKPOINT_PATH`. –ï—Å–ª–∏ –≤—ã –Ω–∞—á–∏–Ω–∞–µ—Ç–µ –æ–±—É—á–µ–Ω–∏–µ —Å 0, —Ç–æ –æ—Å—Ç–∞–≤—å—Ç–µ —ç—Ç–æ –ø–æ–ª–µ `None`","metadata":{"execution":{"iopub.status.busy":"2025-10-12T09:35:16.046537Z","iopub.execute_input":"2025-10-12T09:35:16.046991Z","iopub.status.idle":"2025-10-12T09:35:16.056866Z","shell.execute_reply.started":"2025-10-12T09:35:16.046958Z","shell.execute_reply":"2025-10-12T09:35:16.055166Z"}}},{"cell_type":"code","source":"import shutil\nimport yaml\nfrom pipelines.train import TrainPipeline\nfrom utils.create_config import create_new_config\n\n#–ø—É—Ç—å –¥–æ –≥–ª–∞–≤–Ω–æ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –ø—É—Ç–µ–π –¥–æ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–∞–ø–æ–∫  —Ñ–∞–π–ª–æ–≤\nCONFIG_PATH=\"/kaggle/working/NeuroVoice/configs/train/shtefanov.yaml\" #!–ù–ê–°–¢–†–û–ô–¢–ï\n#–ø—É—Ç—å –¥–æ –≥–æ—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ –æ–±—É—á–µ–Ω–∏—è (–µ—Å–ª–∏ –∏–º–µ–µ—Ç—Å—è)\nTRAIN_FILES = \"/kaggle/input/shtefanov-bd/shtefanov_pope\"             #!–ù–ê–°–¢–†–û–ô–¢–ï\nCHECKPOINT_PATH= None                                                 #!–ù–ê–°–¢–†–û–ô–¢–ï\n\n\nconfig = yaml.safe_load(open(CONFIG_PATH))\n\nif not os.path.exists(CONFIG_PATH):\n    create_new_config()\nconfig[\"data\"][\"base_wav_path\"] = \"/kaggle/input/shtefanov-bd/shtefanov_pope.wav\"\nconfig[\"models\"][\"whisper\"] = \"large-v3\"\nconfig[\"data\"][\"checkpoint_path\"]=CHECKPOINT_PATH\n\nif os.path.exists(TRAIN_FILES) and \"wavs\" in os.listdir(TRAIN_FILES):\n    voice_folderpath=os.path.join(config[\"data\"][\"main_dir\"], os.path.basename(TRAIN_FILES))\n    if os.path.exists(voice_folderpath):\n        shutil.rmtree(voice_folderpath)\n    shutil.copytree(TRAIN_FILES, voice_folderpath)\ntrainpipe=TrainPipeline(config)\ntrainpipe._preprocess_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:42:43.785939Z","iopub.execute_input":"2025-10-12T09:42:43.786231Z","iopub.status.idle":"2025-10-12T09:42:47.295249Z","shell.execute_reply.started":"2025-10-12T09:42:43.786192Z","shell.execute_reply":"2025-10-12T09:42:47.294540Z"}},"outputs":[{"name":"stdout","text":"üòä All mandatory files are ready!\nüòä wavs/ folder is not empty!\nüòä All mandatory files are ready!\nüòä wavs/ folder is not empty!\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"('data/shtefanov/xtts/shtefanov_pope/metadata_train.csv',\n 'data/shtefanov/xtts/shtefanov_pope/metadata_eval.csv')"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# 3. –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ (‚ö†Ô∏è –ù–£–ñ–ù–û GPU ‚ö†Ô∏è)\n\n–û–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –≤—ã –º–æ–∂–µ—Ç–µ –Ω–∞–π—Ç–∏ –≤ –ø–∞–ø–∫–µ, —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤ –∫–æ–Ω—Ñ–∏–≥–µ: `config[\"data\"][\"weights_folder\"]`","metadata":{"execution":{"iopub.status.busy":"2025-10-12T09:37:35.809028Z","iopub.execute_input":"2025-10-12T09:37:35.809370Z","iopub.status.idle":"2025-10-12T09:37:35.814394Z","shell.execute_reply.started":"2025-10-12T09:37:35.809349Z","shell.execute_reply":"2025-10-12T09:37:35.813457Z"}}},{"cell_type":"code","source":"# –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\ntrainpipe.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:42:50.251309Z","iopub.execute_input":"2025-10-12T09:42:50.251809Z","iopub.status.idle":"2025-10-12T09:43:09.932169Z","shell.execute_reply.started":"2025-10-12T09:42:50.251791Z","shell.execute_reply":"2025-10-12T09:43:09.930761Z"}},"outputs":[{"name":"stdout","text":"üòä All mandatory files are ready!\nüòä wavs/ folder is not empty!\nüòä All mandatory files are ready!\nüòä wavs/ folder is not empty!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\nFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c294e9c41454e2794d383b43c1bd9c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25709cc8bc134efe9f55f40cde05592e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"LICENSE.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72f4ac45584248c5a0b860e400219841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"hash.md5:   0%|          | 0.00/32.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05cac9de540d4bd78bd7fc67c996e41f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eaa7a5cee494dd3a29b44bf5d7a0efa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":".gitattributes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5bb750852f7422f847e04c1033f39c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"mel_stats.pth:   0%|          | 0.00/1.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b10c88cc7a31457a8ef44ca921565575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.pth:   0%|          | 0.00/1.87G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7344c8a95a454baa9bac1bdfeda67f52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dvae.pth:   0%|          | 0.00/211M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6477ffc0c06f4b859e35e795a7ee580f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ja-sample.wav:   0%|          | 0.00/285k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c733ad27f5e4cecbded162b1dcb8a75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c420961cddb547c1bf85cc51604837fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tr_sample.wav:   0%|          | 0.00/299k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68433fcca8eb4887abe27ca3f6bcd005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"zh-cn-sample.wav:   0%|          | 0.00/383k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbe8dd30f9a54f36856f9ad46dbdeb50"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"speakers_xtts.pth:   0%|          | 0.00/7.75M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25359a17245a40dea65d0f14c7219966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pt_sample.wav:   0%|          | 0.00/445k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b81d65c89b541e7be857b5846ae1564"}},"metadata":{}},{"name":"stdout","text":"Starting from existing checkpoint /kaggle/input/shtefanov-bd/best_model_35.pth ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/242401921.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/kaggle/working/NeuroVoice/pipelines/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mbase_model_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinetuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_base_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         checkpoint_path =  self.finetuner.finetune_model(\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mbase_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/NeuroVoice/models/tts/xtts_finetuner.py\u001b[0m in \u001b[0;36mfinetune_model\u001b[0;34m(self, device, base_model_path, train_metadata, eval_metadata, language, num_epochs, batch_size, grad_accum, learning_rate, checkpoint_pth_path, output_dir)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Initialize and train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mtrain_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_tts_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconfig_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/xtts/trainer/gpt_trainer.py\u001b[0m in \u001b[0;36minit_from_config\u001b[0;34m(config, samples)\u001b[0m\n\u001b[1;32m    502\u001b[0m                 \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \"\"\"\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mGPTTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/xtts/trainer/gpt_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVoiceBpeTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# init gpt encoder and hifigan decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxtts_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/models/xtts.py\u001b[0m in \u001b[0;36minit_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         self.hifigan_decoder = HifiDecoder(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0minput_sample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0moutput_sample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_sample_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/xtts/hifigan_decoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_sample_rate, output_sample_rate, output_hop_length, ar_mel_length_compression, decoder_input_dim, resblock_type_decoder, resblock_dilation_sizes_decoder, resblock_kernel_sizes_decoder, upsample_rates_decoder, upsample_initial_channel_decoder, upsample_kernel_sizes_decoder, d_vector_dim, cond_d_vector_in_each_upsampling_layer, speaker_encoder_audio_config)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mar_mel_length_compression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar_mel_length_compression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspeaker_encoder_audio_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeaker_encoder_audio_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         self.waveform_decoder = HifiganGenerator(\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0mdecoder_input_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/xtts/hifigan_decoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_channels, out_channels, resblock_type, resblock_dilation_sizes, resblock_kernel_sizes, upsample_kernel_sizes, upsample_initial_channel, upsample_factors, inference_padding, cond_channels, conv_pre_weight_norm, conv_post_weight_norm, conv_post_bias, cond_in_each_up_layer)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsample_initial_channel\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresblock_kernel_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresblock_dilation_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;31m# post convolution layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_post_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/TTS/tts/layers/xtts/hifigan_decoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, channels, kernel_size, dilation)\u001b[0m\n\u001b[1;32m     70\u001b[0m         self.convs2 = nn.ModuleList(\n\u001b[1;32m     71\u001b[0m             [\n\u001b[0;32m---> 72\u001b[0;31m                 weight_norm(\n\u001b[0m\u001b[1;32m     73\u001b[0m                     Conv1d(\n\u001b[1;32m     74\u001b[0m                         \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/utils/parametrizations.py\u001b[0m in \u001b[0;36mweight_norm\u001b[0;34m(module, name, dim)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \"\"\"\n\u001b[1;32m    377\u001b[0m     \u001b[0m_weight_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WeightNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mparametrize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_parametrization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_weight_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     def _weight_norm_compat_hook(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/utils/parametrize.py\u001b[0m in \u001b[0;36mregister_parametrization\u001b[0;34m(module, tensor_name, parametrization, unsafe)\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;31m# We create this early to check for possible errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         parametrizations = ParametrizationList(\n\u001b[0m\u001b[1;32m    607\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mparametrization\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munsafe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/utils/parametrize.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, modules, original, unsafe)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ParametrizationList requires one or more modules.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsafe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munsafe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodules\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m             \u001b[0mself\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_abs_string_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__iadd__\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"ModuleList\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mextend\u001b[0;34m(self, modules)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T09:43:10.462973Z","iopub.execute_input":"2025-10-12T09:43:10.463259Z","iopub.status.idle":"2025-10-12T09:43:10.468784Z","shell.execute_reply.started":"2025-10-12T09:43:10.463240Z","shell.execute_reply":"2025-10-12T09:43:10.468186Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'name': 'shtefanov',\n 'device': 'cuda:0',\n 'audio': {'min_duration': 2.0, 'max_duration': 10.0},\n 'data': {'main_dir': 'data/shtefanov/xtts',\n  'base_wav_path': '/kaggle/input/shtefanov-bd/shtefanov_pope.wav',\n  'weights_folder': 'out/shtefanov/xtts',\n  'checkpoint_path': '/kaggle/input/shtefanov-bd/best_model_35.pth',\n  'reference_audio': '<PASTE_PATH>'},\n 'models': {'whisper': 'large-v3', 'VAD_folder': 'models/VAD'},\n 'train': {'epochs': 15, 'batch_size': 2}}"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"# (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ): –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ .wav —Ñ–∞–π–ª–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å Youtube\n","metadata":{}},{"cell_type":"code","source":"from pytube import YouTube\nimport librosa\nimport os\n\ndef download_youtube_wav_pytube(url, output_path=\"audio.wav\"):\n    \"\"\"Download YouTube audio using pytube\"\"\"\n    yt = YouTube(url)\n    \n    # Get audio stream\n    audio_stream = yt.streams.filter(only_audio=True).first()\n    \n    # Download as MP4\n    temp_file = audio_stream.download(filename=\"temp_audio\")\n    \n    # Convert to WAV using librosa (or you can use ffmpeg)\n    audio, sr = librosa.load(temp_file, sr=22050)\n    librosa.output.write_wav(output_path, audio, sr)\n    \n    # Clean up\n    os.remove(temp_file)\n    \n    return output_path\n\n# Usage\nurl = \"https://youtu.be/EqLevnBwMFA?si=JIPfdB8G-2ZI0WWq\"\nwav_file = download_youtube_wav_pytube(url)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}